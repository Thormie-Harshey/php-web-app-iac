stages:
  - bootstrap
  - init
  - import
  - validate
  - plan
  - apply
  - destroy

image:
  name: hashicorp/terraform:1.10
  entrypoint: ["/bin/sh", "-c"]

.aws_setup:
  id_tokens:
    GITLAB_OIDC_TOKEN:
      aud: https://gitlab.com
  before_script:
    - apk --no-cache add curl python3 py3-pip
    - pip3 install --no-cache-dir awscli --break-system-packages
    - >
      export $(printf "AWS_ACCESS_KEY_ID=%s AWS_SECRET_ACCESS_KEY=%s AWS_SESSION_TOKEN=%s"
      $(aws sts assume-role-with-web-identity
      --role-arn ${ROLE_ARN}
      --role-session-name "GitLabRunner-${CI_PROJECT_ID}-${CI_PIPELINE_ID}"
      --web-identity-token ${GITLAB_OIDC_TOKEN}
      --duration-seconds 3600
      --query 'Credentials.[AccessKeyId,SecretAccessKey,SessionToken]'
      --output text))
    - aws configure set region us-east-1

bootstrap:
  stage: bootstrap
  extends: .aws_setup
  script:
    - echo "Checking if S3 bucket ${TF_STATE_BUCKET} exists..."
    - >
      if aws s3api head-bucket --bucket ${TF_STATE_BUCKET} 2>/dev/null; then
        echo "S3 bucket already exists, skipping creation."
      else
        echo "S3 bucket does not exist, creating it..."
        aws s3api create-bucket --bucket ${TF_STATE_BUCKET}
        echo "Bucket created. Enabling versioning..."
        aws s3api put-bucket-versioning --bucket ${TF_STATE_BUCKET} --versioning-configuration Status=Enabled
      fi
    - echo "Checking if DynamoDB table ${TF_STATE_TABLE} exists..."
    - >
      if aws dynamodb describe-table --table-name ${TF_STATE_TABLE} 2>/dev/null; then
        echo "DynamoDB table already exists, skipping creation."
      else
        echo "DynamoDB table does not exist, creating it..."
        aws dynamodb create-table \
          --table-name ${TF_STATE_TABLE} \
          --attribute-definitions AttributeName=LockID,AttributeType=S \
          --key-schema AttributeName=LockID,KeyType=HASH \
          --billing-mode PAY_PER_REQUEST
      fi
  when: manual
  allow_failure: true

# The 'init' job initializes the Terraform working directory and downloads modules.
# It saves the .terraform directory as an artifact for the next stage.
init:
  stage: init
  extends: .aws_setup
  script:
    - echo "Initializing Terraform with backend configuration..."
    - terraform init -backend-config="bucket=${TF_STATE_BUCKET}" -backend-config="dynamodb_table=${TF_STATE_TABLE}"
  artifacts:
    paths:
      - .terraform/
      - .terraform.lock.hcl
  when: manual
  dependencies: []

# The 'import' job imports the existing backend resources into the state file.
# It depends on the 'init' job to get the initialized working directory.
import:
  stage: import
  extends: .aws_setup
  script:
    - echo "Initializing Terraform with backend configuration..."
    - terraform init -reconfigure -backend-config="bucket=${TF_STATE_BUCKET}" -backend-config="dynamodb_table=${TF_STATE_TABLE}"
    - echo "Importing S3 state bucket and DynamoDB lock table..."
    - terraform import module.s3.aws_s3_bucket.state_bucket "${TF_STATE_BUCKET}"
    - terraform import module.dynamodb.aws_dynamodb_table.state_lock_table "${TF_STATE_TABLE}"
  artifacts:
    paths:
      - .terraform/
      - .terraform.lock.hcl
  when: manual
  dependencies:
    - init

validate:
  stage: validate
  extends: .aws_setup
  script:
    - terraform init -reconfigure -backend-config="bucket=${TF_STATE_BUCKET}" -backend-config="dynamodb_table=${TF_STATE_TABLE}"
    - terraform fmt -check -recursive
    - terraform validate
  dependencies:
    - import

plan:
  stage: plan
  extends: .aws_setup
  script:
    - terraform init -reconfigure -backend-config="bucket=${TF_STATE_BUCKET}" -backend-config="dynamodb_table=${TF_STATE_TABLE}"
    - terraform plan -out="planfile"
    - terraform show -no-color planfile > planfile.txt
  artifacts:
    paths:
      - planfile
      - .terraform.lock.hcl
    reports:
      terraform: planfile
  dependencies:
    - import

apply:
  stage: apply
  extends: .aws_setup
  script:
    - terraform init -reconfigure -backend-config="bucket=${TF_STATE_BUCKET}" -backend-config="dynamodb_table=${TF_STATE_TABLE}"
    - terraform apply -input=false "planfile"
    - terraform output > output.txt
  artifacts:
    paths:
      - output.txt
    reports:
      terraform: output.txt
  when: manual
  dependencies:
    - plan

destroy:
  stage: destroy
  extends: .aws_setup
  script:
    - terraform init -reconfigure -backend-config="bucket=${TF_STATE_BUCKET}" -backend-config="dynamodb_table=${TF_STATE_TABLE}"
    - terraform destroy --auto-approve
  when: manual
  dependencies:
    - import